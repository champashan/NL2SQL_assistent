# -*- coding: utf-8 -*-
"""Копия блокнота "Копия блокнота "SpiderSQL.ipynb""

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sVkduz6Zt3-uKXgIbFaVB3A-jWIVvEPY

NLtoSQL Assistant
"""


import sys
sys.path.append('UnifiedSKG')

import os
import time
import torch
import datasets
from googletrans import Translator 
from transformers import (
    HfArgumentParser,
    set_seed,
    AutoTokenizer
)
from utils.configue import Configure
from utils.training_arguments import WrappedSeq2SeqTrainingArguments

from filelock import FileLock
import nltk
with FileLock(".lock") as lock:
    nltk.download("punkt", quiet=True)
    nltk.download("stopwords", quiet=True)

sys.argv = ['/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py',
            
            '--cfg', 'Salesforce/T5_base_prefix_spider_with_cell_value.cfg', 
            '--output_dir', './tmp']
parser = HfArgumentParser((WrappedSeq2SeqTrainingArguments,))
training_args, = parser.parse_args_into_dataclasses()
set_seed(training_args.seed)
args = Configure.Get(training_args.cfg)

tokenizer = AutoTokenizer.from_pretrained("hkunlp/from_all_T5_base_prefix_spider_with_cell_value2", use_fast=False)
from models.unified.prefixtuning import Model
model = Model(args)
model.load("hkunlp/from_all_T5_base_prefix_spider_with_cell_value2")

translator = Translator()
inpt = input("Введите запрос на естественном языке:\n")
question = translator.translate(inpt, dest='en')
struct_in = "| concert_singer | stadium : stadium_id , location , name , capacity , highest , lowest , average | singer : singer_id , name , country ( France ) , song_name , song_release_year , age , is_male | concert : concert_id , concert_name , theme , stadium_id , year | singer_in_concert : concert_id , singer_id"
text_in = question.text
translator = Translator()
tokenized_txt = tokenizer([text_in], max_length=1024, padding="max_length", truncation=True)
pred = tokenizer.batch_decode(
    model.generate(
      torch.LongTensor(tokenized_txt.data['input_ids']),
      torch.LongTensor(tokenized_txt.data['attention_mask']),
      num_beams=1, 
      max_length=256
      ), 
    skip_special_tokens=True 
) 
print("=====SQL запрос=====")
print(*pred)
